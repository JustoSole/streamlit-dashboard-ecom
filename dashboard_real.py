import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
from datetime import datetime, timedelta
import json
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

# ConfiguraciÃ³n de la pÃ¡gina y tema personalizado
st.set_page_config(
    layout="wide",
    page_title="Customer Analytics Dashboard",
    page_icon="ğŸ‘¥",
    initial_sidebar_state="expanded"
)

# Global CSS for styling
st.markdown("""
<style>
    /* Main dashboard font */
    body, .stApp { /* Apply font to the whole app */
        font-family: 'Source Sans Pro', 'Helvetica Neue', Helvetica, Arial, sans-serif;
    }

    /* Headers styling */
    h1, h2, h3 { /* Targeting Streamlit's markdown headers */
        color: #005A5A; /* Darker Teal for headers */
        font-weight: 600;
    }
    
    /* Improve st.metric look and feel */
    .stMetric {
        background-color: #FFFFFF;
        border-radius: 8px;
        padding: 18px 20px; /* Adjusted padding */
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.05); /* Softer shadow */
        border: 1px solid #E0E0E0;
        transition: box-shadow 0.3s ease-in-out;
    }
    .stMetric:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.08);
    }

    /* Style the help text within st.metric */
    .stMetric [data-testid="stMetricHelp"] p {
        font-style: italic;
        font-size: 0.82rem; /* Slightly smaller */
        color: #555E67; /* Softer color */
        line-height: 1.3;
        margin-top: 5px; /* Add some space above help text */
    }
    .stMetric label { /* Metric Label */
        font-weight: 500; /* Make label a bit bolder */
        color: #4B5563; /* Custom color for label */
    }
    .stMetric div[data-testid="stMetricValue"] { /* Metric Value */
        font-size: 2.1rem; /* Slightly larger value */
        font-weight: 600;
        color: #008080; /* Teal color for value */
    }
     .stMetric div[data-testid="stMetricDelta"] { /* Metric Delta */
        font-size: 0.85rem;
        font-weight: 500;
    }


    /* General descriptive text under tabs or section titles */
    .dashboard-subtext { /* Renamed class for clarity */
        font-size: 0.9rem;
        color: #4A5568; /* Slightly muted color */
        margin-bottom: 1.2rem; /* Space below description */
        font-style: normal;
        line-height: 1.5;
    }
    
    /* Style st.tabs */
    .stTabs [data-baseweb="tab-list"] {
        gap: 12px; /* Space between tabs */
        border-bottom: 1px solid #D1D5DB; /* Lighter border for tab list */
        padding-bottom: 0px; /* Align with bottom border of active tab */
    }
    .stTabs [data-baseweb="tab"] {
        height: 40px;
        white-space: pre-wrap;
        background-color: transparent; /* Make inactive tabs blend more */
        border-radius: 6px 6px 0px 0px;
        padding: 0px 16px; /* Adjust padding */
        margin-bottom: -1px; /* Overlap with bottom border */
        border: 1px solid transparent; /* For border consistency on hover/active */
        font-weight: 500;
        color: #4B5563; /* Inactive tab text color */
    }
    .stTabs [data-baseweb="tab"]:hover {
        background-color: #E5E7EB; /* Light hover effect */
        color: #1F2937;
    }
    .stTabs [data-baseweb="tab"][aria-selected="true"] {
        background-color: #FFFFFF; /* Active tab background (secondaryBackgroundColor) */
        color: #008080; /* Active tab text color (primaryColor) */
        border-color: #D1D5DB #D1D5DB #FFFFFF; /* Border for active tab */
        font-weight: 600;
    }

    /* Warnings and infos */
    .stAlert {
        border-radius: 6px;
    }
    .stAlert[data-baseweb="alert"] > div:first-child { /* Icon part */
        padding-top: 10px !important; 
    }
    .stAlert[data-baseweb="alert"] p { /* Text part */
        font-size: 0.88rem;
    }
    
    /* Sidebar styling for missing data points */
    [data-testid="stSidebar"] .stAlert[data-baseweb="alert"] p { /* Text part in sidebar warnings */
        font-size: 0.8rem;
    }
    [data-testid="stSidebar"] h3 { /* Sidebar headers */
        color: #006A6A; /* Slightly different teal for sidebar headers */
        font-size: 1.1rem;
    }
    [data-testid="stSidebar"] .stRadio > label { /* Sidebar radio labels */
        font-size: 0.95rem;
    }
    
    /* Style Plotly chart titles (if they render as SVG text with specific classes - usually not directly targetable for sub-parts like <sub>) */
    /* Subtitles within Plotly charts are best handled using the <br><sub>HTML</sub> approach in the title string itself */

    /* General st.info styling */
    .stInfo {
        background-color: #E0F2FE !important; /* Light blue background */
        border: 1px solid #7DD3FC !important; /* Blue border */
        color: #0C5475 !important; /* Darker blue text */
        border-radius: 6px !important;
    }
    .stInfo p {
         color: #0C5475 !important;
         font-size: 0.88rem;
    }


</style>
""", unsafe_allow_html=True)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# Carga de datos reales
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
DATA_DIR = "bigquery_data_20250513_171339"
missing_data_points = []

@st.cache_data(ttl=3600)
def load_real_data():
    """Carga los datos reales desde los archivos CSV."""
    global missing_data_points
    try:
        # Cargar datos de Ã³rdenes
        df_items = pd.read_csv(f"{DATA_DIR}/SHOPIFY_ORDERS_LINEITEMS.csv")
        df_items['ORDER_CREATE_DATE'] = pd.to_datetime(df_items['ORDER_CREATE_DATE']).dt.tz_localize(None)
        # Asegurar que USER_EMAIL es string y no hay NaN para evitar errores en groupby
        df_items['USER_EMAIL'] = df_items['USER_EMAIL'].astype(str).fillna('unknown_email')
        df_items['PRODUCT_NAME'] = df_items['PRODUCT_NAME'].astype(str).fillna('Unknown Product')

        
        # Cargar datos de sesiones
        df_sessions = pd.read_csv(f"{DATA_DIR}/GA_SESSIONS.csv")
        df_sessions['EVENT_DATE'] = pd.to_datetime(df_sessions['EVENT_DATE']).dt.tz_localize(None)
        if 'BOUNCE_RATE' not in df_sessions.columns:
            missing_data_points.append("Tasa de Rebote (Bounce Rate) de Sesiones (columna 'BOUNCE_RATE' no encontrada en GA_SESSIONS)")
        if 'AVG_SESSION_DURATION' not in df_sessions.columns:
            missing_data_points.append("DuraciÃ³n Promedio de SesiÃ³n (columna 'AVG_SESSION_DURATION' no encontrada en GA_SESSIONS)")
        if 'ADD_TO_CART_EVENTS' not in df_sessions.columns or 'CHECKOUT_INITIATED_EVENTS' not in df_sessions.columns: # Example columns
            missing_data_points.append("Tasa de Abandono de Carrito (CAR) (datos de eventos de carrito no encontrados)")

        
        # Cargar datos de Ã³rdenes GA
        df_ga_orders = pd.read_csv(f"{DATA_DIR}/GA_ORDERS.csv")
        df_ga_orders['Date'] = pd.to_datetime(df_ga_orders['Date']).dt.tz_localize(None)
        df_ga_orders['Transaction_ID'] = df_ga_orders['Transaction_ID'].astype(str)
        df_items['ORDER_GID_STR'] = df_items['ORDER_GID'].astype(str) # Para el merge
        
        # Cargar datos de campaÃ±as
        df_ads = pd.read_csv(f"{DATA_DIR}/GA_ADS_CAMPAIGNS.csv")
        df_ads['Date'] = pd.to_datetime(df_ads['Date']).dt.tz_localize(None)
        if 'LEADS_GENERATED' not in df_ads.columns: # Example column
            missing_data_points.append("Costo por Lead (CPL) (datos de leads no encontrados)")
        
        # NPS Data
        missing_data_points.append("Ãndice de SatisfacciÃ³n NPS (datos de NPS generalmente provienen de encuestas y no estÃ¡n en los CSVs)")
        
        return df_items, df_sessions, df_ga_orders, df_ads
    except Exception as e:
        st.error(f"Error cargando los datos: {str(e)}")
        return None, None, None, None

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# Funciones de anÃ¡lisis EDA
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def analyze_numerical_columns(df, columns):
    """AnÃ¡lisis estadÃ­stico de columnas numÃ©ricas."""
    stats_df = pd.DataFrame()
    for col in columns:
        stats = df[col].describe()
        stats_df[col] = stats
    return stats_df

def analyze_categorical_columns(df, columns):
    """AnÃ¡lisis de columnas categÃ³ricas."""
    cat_stats = {}
    for col in columns:
        value_counts = df[col].value_counts()
        cat_stats[col] = {
            'unique_values': len(value_counts),
            'top_values': value_counts.head(5).to_dict(),
            'missing_values': df[col].isnull().sum()
        }
    return cat_stats

def plot_correlation_matrix(df, columns):
    """Genera matriz de correlaciÃ³n para columnas numÃ©ricas."""
    corr_matrix = df[columns].corr()
    fig = px.imshow(corr_matrix,
                    labels=dict(color="CorrelaciÃ³n"),
                    x=columns,
                    y=columns,
                    color_continuous_scale='RdBu_r')
    fig.update_layout(title="Matriz de CorrelaciÃ³n")
    return fig

def plot_distribution(df, column, bins=30):
    """Genera grÃ¡fico de distribuciÃ³n para una columna numÃ©rica."""
    fig = px.histogram(df, x=column, nbins=bins,
                      title=f"DistribuciÃ³n de {column}")
    return fig

def plot_time_series(df, date_column, value_column, title):
    """Genera grÃ¡fico de serie temporal."""
    fig = px.line(df, x=date_column, y=value_column,
                  title=title)
    return fig

def analyze_outliers(df, column):
    """Detecta y analiza outliers en una columna numÃ©rica."""
    if column not in df.columns or df[column].isnull().all():
        return {
            'outliers_count': 0,
            'outliers_percentage': 0,
            'lower_bound': np.nan,
            'upper_bound': np.nan,
            'error': f"Columna {column} no encontrada o vacÃ­a."
        }
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
    return {
        'outliers_count': len(outliers),
        'outliers_percentage': len(outliers) / len(df) * 100,
        'lower_bound': lower_bound,
        'upper_bound': upper_bound
    }

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# Carga y procesamiento de datos
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
df_items, df_sessions, df_ga_orders, df_ads = load_real_data()

if df_items is None or df_sessions is None or df_ga_orders is None or df_ads is None:
    st.error("No se pudieron cargar algunos o todos los datos. Por favor, verifica que los archivos CSV existan y su contenido.")
    st.stop()

# Sidebar con diseÃ±o mejorado
with st.sidebar:
    # st.image("https://via.placeholder.com/200x60?text=CUSTOMER+ANALYTICS", width=200) # Eliminada o comentada
    st.markdown("---")
    
    st.markdown("### ğŸ“… Filtro de Fechas Global")
    st.markdown("Selecciona el rango de fechas para el anÃ¡lisis general del dashboard:")
    
    # Obtener fechas mÃ­nimas y mÃ¡ximas de los datos para los defaults del date_input
    min_date_items_sidebar = df_items['ORDER_CREATE_DATE'].min() if not df_items.empty else pd.Timestamp.min.tz_localize(None)
    max_date_items_sidebar = df_items['ORDER_CREATE_DATE'].max() if not df_items.empty else pd.Timestamp.max.tz_localize(None)
    
    min_date_sessions_sidebar = df_sessions['EVENT_DATE'].min() if not df_sessions.empty else pd.Timestamp.min.tz_localize(None)
    max_date_sessions_sidebar = df_sessions['EVENT_DATE'].max() if not df_sessions.empty else pd.Timestamp.max.tz_localize(None)

    min_date_ga_orders_sidebar = df_ga_orders['Date'].min() if not df_ga_orders.empty else pd.Timestamp.min.tz_localize(None)
    max_date_ga_orders_sidebar = df_ga_orders['Date'].max() if not df_ga_orders.empty else pd.Timestamp.max.tz_localize(None)

    min_date_ads_sidebar = df_ads['Date'].min() if not df_ads.empty else pd.Timestamp.min.tz_localize(None)
    max_date_ads_sidebar = df_ads['Date'].max() if not df_ads.empty else pd.Timestamp.max.tz_localize(None)

    # Global min and max dates for the date picker constraints
    overall_min_date = min(min_date_items_sidebar, min_date_sessions_sidebar, min_date_ga_orders_sidebar, min_date_ads_sidebar)
    overall_max_date = max(max_date_items_sidebar, max_date_sessions_sidebar, max_date_ga_orders_sidebar, max_date_ads_sidebar)

    # Default start date: 12 months before the overall_max_date, or 12 months before today if no data
    default_start_date = (overall_max_date - pd.DateOffset(months=12)).date() \
        if pd.notnull(overall_max_date) and overall_max_date != pd.Timestamp.max.tz_localize(None) \
        else (datetime.now() - timedelta(days=365)).date()
    
    # Default end date: overall_max_date, or today if no data
    default_end_date = overall_max_date.date() \
        if pd.notnull(overall_max_date) and overall_max_date != pd.Timestamp.max.tz_localize(None) \
        else datetime.now().date()

    start_date_input, end_date_input = st.date_input(
        "Selecciona el Rango de Fechas:",
        value=[default_start_date, default_end_date],
        min_value=overall_min_date.date() if pd.notnull(overall_min_date) and overall_min_date != pd.Timestamp.min.tz_localize(None) else None,
        max_value=overall_max_date.date() if pd.notnull(overall_max_date) and overall_max_date != pd.Timestamp.max.tz_localize(None) else None,
        help="Este filtro de fechas se aplica globalmente a la mayorÃ­a de los anÃ¡lisis del dashboard."
        )

    # Convertir fechas a datetime
    start_date = pd.to_datetime(start_date_input)
    end_date = pd.to_datetime(end_date_input)

    st.markdown("---")
    st.markdown("### ğŸ“– GuÃ­a del Dashboard")
    st.markdown("""
        Este dashboard proporciona un anÃ¡lisis detallado de los clientes basado en los datos de eCommerce.
        Utiliza los filtros de perÃ­odo para enfocar el anÃ¡lisis en rangos de tiempo especÃ­ficos.
        Cada pestaÃ±a se centra en un aspecto diferente del comportamiento y valor del cliente.
    """)

# Filtrar DataFrames principales por el rango de fechas seleccionado
df_items_filtered = df_items[df_items['ORDER_CREATE_DATE'].between(start_date, end_date)]
df_sessions_filtered = df_sessions[df_sessions['EVENT_DATE'].between(start_date, end_date)]
df_ga_orders_filtered = df_ga_orders[df_ga_orders['Date'].between(start_date, end_date)]
df_ads_filtered = df_ads[df_ads['Date'].between(start_date, end_date)]


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# Dashboard con Streamlit
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
st.title("ğŸ‘¥ Customer Analytics Dashboard")

st.warning("""
    **âš ï¸ ESTE DASHBOARD ES UNA PRUEBA DE CONCEPTO (POC) âš ï¸**

    Los datos mostrados aquÃ­ son una **muestra utilizada para el desarrollo** y **NO deben usarse para tomar decisiones de negocio.**
    
    El objetivo actual es recopilar feedback sobre:
    - Â¿QuÃ© informaciÃ³n adicional serÃ­a valiosa?
    - Â¿CÃ³mo podemos mejorar la visualizaciÃ³n de los datos actuales?
    - Â¿Hay secciones o grÃ¡ficos que no se entienden claramente?
    
    """, icon="ğŸ“¢")

# Tabs segÃºn customer_analysis.md
tab_vision, tab_frecuencia, tab_valor, tab_comportamiento, tab_trafico, tab_costo, tab_nps = st.tabs([
    "ğŸŒ VisiÃ³n General del Cliente", 
    "ğŸ”„ Frecuencia y Recurrencia", 
    "ğŸ’° Valor del Cliente",
    "ğŸ›’ Comportamiento de Compra", 
    "ğŸ“ˆ Traffic Analytics", 
    "ğŸ’¸ Costo de AdquisiciÃ³n",
    "ğŸ˜Š NPS"
])

# Helper function para evitar errores con data vacÃ­a en grÃ¡ficos
def safe_plotly_chart(fig, use_container_width=True):
    if fig is not None:
        st.plotly_chart(fig, use_container_width=use_container_width)
    else:
        st.info("No hay datos suficientes para mostrar este grÃ¡fico con los filtros seleccionados.")

# Tab 1: VisiÃ³n General del Cliente
with tab_vision:
    st.markdown("### ğŸŒ VisiÃ³n General del Cliente")
    st.markdown("<div class='dashboard-subtext'>Una mirada a quiÃ©nes son tus clientes, de dÃ³nde vienen y cÃ³mo se distribuyen, segÃºn el perÃ­odo seleccionado.</div>", unsafe_allow_html=True)

    # --- MÃ©trica Global Independiente ---
    if not df_items.empty:
        total_historical_customers = df_items['USER_EMAIL'].nunique()
        st.metric(
            label="ğŸ‘¥ Total Clientes HistÃ³ricos (Global)",
            value=f"{total_historical_customers:,}",
            help="NÃºmero total de clientes Ãºnicos (`USER_EMAIL`) identificados en todo el historial de datos de Ã³rdenes (`SHOPIFY_ORDERS_LINEITEMS.csv`). No se aplica ningÃºn filtro de fecha a esta mÃ©trica."
        )
    else:
        st.warning("No hay datos de Ã³rdenes para calcular el total de clientes histÃ³ricos.")
    st.markdown("---")

    # --- Selector de PerÃ­odo para la PestaÃ±a VisiÃ³n General ---
    first_purchase_dates_all_time = df_items.groupby('USER_EMAIL')['ORDER_CREATE_DATE'].min().rename('FIRST_PURCHASE_DATE_GLOBAL')
    
    df_items_for_tab_vision = pd.DataFrame()
    current_start_date_tab_vision = None
    current_end_date_tab_vision = None
    selected_period_label_tab_vision = "Usar Filtro Global de Fechas" # Default
    subtitle_period_string_tab_vision = ""

    if not df_items.empty and pd.notnull(df_items['ORDER_CREATE_DATE'].max()):
        data_max_date_tab = df_items['ORDER_CREATE_DATE'].max()
        data_min_date_tab = df_items['ORDER_CREATE_DATE'].min()

        periods_options_tab = [
            (3, "Ãšltimos 3 Meses"), 
            (6, "Ãšltimos 6 Meses"), 
            (12, "Ãšltimos 12 Meses"), 
            (None, "HistÃ³rico Completo"), 
            ("GLOBAL", "Usar Filtro Global de Fechas")
        ]
        period_labels_tab = [label for _, label in periods_options_tab]
        
        selected_period_label_tab_vision = st.radio(
            "Selecciona el perÃ­odo para el anÃ¡lisis en esta pestaÃ±a:",
            options=period_labels_tab,
            horizontal=True,
            index=len(periods_options_tab) - 1, 
            key="tab_vision_period_selector"
        )

        if selected_period_label_tab_vision == "Usar Filtro Global de Fechas":
            df_items_for_tab_vision = df_items_filtered.copy()
            current_start_date_tab_vision = start_date # Global start_date from sidebar
            current_end_date_tab_vision = end_date   # Global end_date from sidebar
            if pd.notnull(current_start_date_tab_vision) and pd.notnull(current_end_date_tab_vision):
                subtitle_period_string_tab_vision = f"PerÃ­odo Global: {current_start_date_tab_vision.strftime('%d %b %Y')} - {current_end_date_tab_vision.strftime('%d %b %Y')}"
            else:
                 subtitle_period_string_tab_vision = "Filtro Global no definido"
        else:
            num_months_tab = None
            is_full_history_tab = False
            for num_m, lbl in periods_options_tab:
                if lbl == selected_period_label_tab_vision:
                    num_months_tab = num_m
                    if num_m is None and lbl == "HistÃ³rico Completo":
                        is_full_history_tab = True
                    break
            
            if is_full_history_tab:
                current_start_date_tab_vision = data_min_date_tab
                current_end_date_tab_vision = data_max_date_tab
                df_items_for_tab_vision = df_items.copy()
                subtitle_period_string_tab_vision = f"HistÃ³rico Completo: {data_min_date_tab.strftime('%d %b %Y')} - {data_max_date_tab.strftime('%d %b %Y')}"
            elif num_months_tab is not None:
                current_start_date_tab_vision = data_max_date_tab - pd.DateOffset(months=num_months_tab)
                if current_start_date_tab_vision < data_min_date_tab:
                    current_start_date_tab_vision = data_min_date_tab
                current_end_date_tab_vision = data_max_date_tab
                df_items_for_tab_vision = df_items[df_items['ORDER_CREATE_DATE'].between(current_start_date_tab_vision, current_end_date_tab_vision)]
                subtitle_period_string_tab_vision = f"{selected_period_label_tab_vision}: {current_start_date_tab_vision.strftime('%d %b %Y')} - {current_end_date_tab_vision.strftime('%d %b %Y')}"
    else:
        st.warning("No hay datos de Ã³rdenes disponibles para la pestaÃ±a de VisiÃ³n General.")
        # Set dummy df to avoid errors, or st.stop() if preferred
        df_items_for_tab_vision = pd.DataFrame(columns=df_items.columns) 
        current_start_date_tab_vision = pd.Timestamp.min.tz_localize(None)
        current_end_date_tab_vision = pd.Timestamp.max.tz_localize(None)
        subtitle_period_string_tab_vision = "Datos no disponibles"


    st.markdown(f"#### Resumen para: {selected_period_label_tab_vision}")
    st.markdown(f"<div class='dashboard-subtext' style='margin-bottom:1rem;'>{subtitle_period_string_tab_vision}</div>", unsafe_allow_html=True)

    if not df_items_for_tab_vision.empty and pd.notnull(current_start_date_tab_vision) and pd.notnull(current_end_date_tab_vision):
        # --- SecciÃ³n 1: MÃ©tricas Clave del PerÃ­odo Seleccionado ---
        # Ajustar columnas para incluir los nuevos KPIs de porcentaje
        col_metric1, col_metric2, col_metric3, col_metric4, col_metric5 = st.columns(5)

        total_unique_in_tab_period = df_items_for_tab_vision['USER_EMAIL'].nunique()
        with col_metric1:
            st.metric(label="Total Clientes Ãšnicos", value=f"{total_unique_in_tab_period:,}",
                      help=f"NÃºmero de clientes Ãºnicos (`USER_EMAIL`) que realizaron al menos una compra dentro del perÃ­odo seleccionado para esta pestaÃ±a ({subtitle_period_string_tab_vision}). Se basa en `SHOPIFY_ORDERS_LINEITEMS.csv` filtrado.")

        df_enriched_tab_vision = df_items_for_tab_vision.merge(first_purchase_dates_all_time.reset_index(), on='USER_EMAIL', how='left')
        
        new_in_tab_period = 0
        if 'FIRST_PURCHASE_DATE_GLOBAL' in df_enriched_tab_vision.columns: 
            new_in_tab_period = df_enriched_tab_vision[
                df_enriched_tab_vision['FIRST_PURCHASE_DATE_GLOBAL'].between(current_start_date_tab_vision, current_end_date_tab_vision)
            ]['USER_EMAIL'].nunique()
        
        recurrent_in_tab_period = total_unique_in_tab_period - new_in_tab_period
        
        with col_metric2:
            st.metric(label="Clientes Nuevos", value=f"{new_in_tab_period:,}",
                      help=f"Clientes Ãºnicos (`USER_EMAIL`) cuya primera compra *global* (histÃ³rica, de `SHOPIFY_ORDERS_LINEITEMS.csv`) ocurriÃ³ *dentro* del perÃ­odo seleccionado para esta pestaÃ±a ({subtitle_period_string_tab_vision}), y que tambiÃ©n realizaron una compra en este mismo perÃ­odo.")
        with col_metric3:
            st.metric(label="Clientes Recurrentes", value=f"{recurrent_in_tab_period:,}",
                      help=f"Clientes Ãºnicos (`USER_EMAIL`) que realizaron compras en el perÃ­odo seleccionado para esta pestaÃ±a ({subtitle_period_string_tab_vision}), y cuya primera compra *global* (histÃ³rica) ocurriÃ³ *antes* del inicio de este perÃ­odo seleccionado.")

        # Calcular porcentajes para los nuevos KPIs
        perc_new_in_tab_period = 0
        perc_recurrent_in_tab_period = 0
        if total_unique_in_tab_period > 0:
            perc_new_in_tab_period = (new_in_tab_period / total_unique_in_tab_period) * 100
            perc_recurrent_in_tab_period = (recurrent_in_tab_period / total_unique_in_tab_period) * 100

        with col_metric4:
            st.metric(label="% Clientes Nuevos", 
                      value=f"{perc_new_in_tab_period:.2f}%" if total_unique_in_tab_period > 0 else "0%",
                      help=f"Porcentaje que representan los 'Clientes Nuevos' sobre el 'Total Clientes Ãšnicos' en el perÃ­odo seleccionado para esta pestaÃ±a ({subtitle_period_string_tab_vision}).")
        
        with col_metric5:
            st.metric(label="% Clientes Recurrentes", 
                      value=f"{perc_recurrent_in_tab_period:.2f}%" if total_unique_in_tab_period > 0 else "0%",
                      help=f"Porcentaje que representan los 'Clientes Recurrentes' sobre el 'Total Clientes Ãšnicos' en el perÃ­odo seleccionado para esta pestaÃ±a ({subtitle_period_string_tab_vision}).")

        # El cÃ³digo del pie chart ha sido eliminado de esta secciÃ³n.
        
        st.markdown("---")
        # --- SecciÃ³n 2: EvoluciÃ³n Mensual dentro del PerÃ­odo Seleccionado ---
        st.markdown("##### EvoluciÃ³n Mensual")
        # col_evo1, col_evo2 = st.columns(2) # Eliminado para disposiciÃ³n vertical

        # GrÃ¡fico de EvoluciÃ³n de Clientes Ãšnicos Mensuales
        monthly_unique_tab = df_items_for_tab_vision.groupby(
            pd.Grouper(key='ORDER_CREATE_DATE', freq='M')
        )['USER_EMAIL'].nunique().reset_index()
        monthly_unique_tab.rename(columns={'USER_EMAIL': 'Clientes Ãšnicos Mensuales', 'ORDER_CREATE_DATE': 'Mes'}, inplace=True)
        
        if not monthly_unique_tab.empty:
            fig_title_evo_unique = (
                f"EvoluciÃ³n de Clientes Ãšnicos Mensuales<br>"
                f"<sub style='font-size:0.75em;'>PerÃ­odo: {subtitle_period_string_tab_vision}. Conteo de clientes (`USER_EMAIL`) Ãºnicos con compras por mes desde `SHOPIFY_ORDERS_LINEITEMS.csv`.</sub>"
            )
            fig_evo_unique = px.line(
                monthly_unique_tab, x='Mes', y='Clientes Ãšnicos Mensuales', title=fig_title_evo_unique, markers=True
            )
            fig_evo_unique.update_layout(title_font_size=15, margin=dict(t=60, b=20, l=20, r=20), height=350)
            safe_plotly_chart(fig_evo_unique)
        else:
            st.caption("No hay datos de evoluciÃ³n de clientes Ãºnicos.")

        # GrÃ¡fico de EvoluciÃ³n de Nuevos vs. Recurrentes Mensual (Barras Apiladas)
        df_evolution_source_tab = df_items_for_tab_vision.merge(
            first_purchase_dates_all_time.reset_index(), on='USER_EMAIL', how='left'
        )
        if not df_evolution_source_tab.empty and 'FIRST_PURCHASE_DATE_GLOBAL' in df_evolution_source_tab.columns:
            df_evolution_source_tab['ORDER_MONTH_PERIOD'] = df_evolution_source_tab['ORDER_CREATE_DATE'].dt.to_period('M')
            df_evolution_source_tab['FIRST_PURCHASE_MONTH_PERIOD_GLOBAL'] = pd.to_datetime(df_evolution_source_tab['FIRST_PURCHASE_DATE_GLOBAL']).dt.to_period('M')
            df_evolution_source_tab['CUSTOMER_TYPE_FOR_MONTH'] = np.select(
                [df_evolution_source_tab['ORDER_MONTH_PERIOD'] == df_evolution_source_tab['FIRST_PURCHASE_MONTH_PERIOD_GLOBAL'],
                 df_evolution_source_tab['ORDER_MONTH_PERIOD'] > df_evolution_source_tab['FIRST_PURCHASE_MONTH_PERIOD_GLOBAL']],
                ['Nuevo en Mes', 'Recurrente en Mes'], default='Indeterminado' 
            )
            df_evo_classified_tab = df_evolution_source_tab[df_evolution_source_tab['CUSTOMER_TYPE_FOR_MONTH'] != 'Indeterminado']

            if not df_evo_classified_tab.empty:
                monthly_counts_tab = df_evo_classified_tab.groupby(
                    ['ORDER_MONTH_PERIOD', 'CUSTOMER_TYPE_FOR_MONTH']
                )['USER_EMAIL'].nunique().reset_index()
                monthly_counts_tab.rename(columns={'ORDER_MONTH_PERIOD': 'Mes', 'CUSTOMER_TYPE_FOR_MONTH': 'Tipo de Cliente', 'USER_EMAIL': 'NÃºmero de Clientes'}, inplace=True)
                monthly_counts_tab['Mes'] = monthly_counts_tab['Mes'].dt.to_timestamp()

                if not monthly_counts_tab.empty:
                    pivot_df_tab = monthly_counts_tab.pivot_table(index='Mes', columns='Tipo de Cliente', values='NÃºmero de Clientes', fill_value=0).reset_index()
                    if 'Nuevo en Mes' not in pivot_df_tab.columns: pivot_df_tab['Nuevo en Mes'] = 0
                    if 'Recurrente en Mes' not in pivot_df_tab.columns: pivot_df_tab['Recurrente en Mes'] = 0
                    pivot_df_tab.rename(columns={'Nuevo en Mes': 'Num_Nuevos', 'Recurrente en Mes': 'Num_Recurrentes'}, inplace=True)
                    pivot_df_tab['Total_Clientes_Mes'] = pivot_df_tab['Num_Nuevos'] + pivot_df_tab['Num_Recurrentes']
                    pivot_df_tab['Porc_Nuevos'] = np.where(pivot_df_tab['Total_Clientes_Mes'] > 0, (pivot_df_tab['Num_Nuevos'] / pivot_df_tab['Total_Clientes_Mes']) * 100, 0)
                    pivot_df_tab['Porc_Recurrentes'] = np.where(pivot_df_tab['Total_Clientes_Mes'] > 0, (pivot_df_tab['Num_Recurrentes'] / pivot_df_tab['Total_Clientes_Mes']) * 100, 0)
                    
                    data_bar_final_tab = pd.merge(monthly_counts_tab, pivot_df_tab[['Mes', 'Total_Clientes_Mes', 'Num_Nuevos', 'Porc_Nuevos', 'Num_Recurrentes', 'Porc_Recurrentes']], on='Mes', how='left')
                    
                    fig_stacked_bar_tab_title = (
                        f"EvoluciÃ³n Mensual: Nuevos vs. Recurrentes<br>"
                        f"<sub style='font-size:0.75em;'>PerÃ­odo: {subtitle_period_string_tab_vision}. 'Nuevo en Mes': 1Âª compra global en ese mes. 'Recurrente': 1Âª compra global anterior. De `SHOPIFY_ORDERS_LINEITEMS.csv`.</sub>"
                    )
                    fig_stacked_bar_tab = px.bar(
                        data_bar_final_tab, x='Mes', y='NÃºmero de Clientes', color='Tipo de Cliente', title=fig_stacked_bar_tab_title,
                        barmode='stack', custom_data=['Total_Clientes_Mes', 'Num_Nuevos', 'Porc_Nuevos', 'Num_Recurrentes', 'Porc_Recurrentes']
                    )
                    fig_stacked_bar_tab.update_traces(
                        hovertemplate=("<b>%{x|%b %Y}</b><br><br>" + "Total Clientes: %{customdata[0]} (100%)<br>" + "Clientes Nuevos: %{customdata[1]} (%{customdata[2]:.1f}%)<br>" + "Clientes Recurrentes: %{customdata[3]} (%{customdata[4]:.1f}%)" + "<extra></extra>")
                    )
                    fig_stacked_bar_tab.update_layout(title_font_size=15, margin=dict(t=60, b=20, l=20, r=20), height=350, legend_title_text='Tipo Cliente')
                    safe_plotly_chart(fig_stacked_bar_tab)
                else:
                    st.caption("No hay datos de evoluciÃ³n nuevos vs recurrentes.")
            else:
                st.caption("No se pudieron clasificar clientes para evoluciÃ³n nuevos vs recurrentes.")
        else:
            st.caption("Datos insuficientes para evoluciÃ³n nuevos vs recurrentes.")
        
        st.markdown("---")
        # --- SecciÃ³n 3: AnÃ¡lisis Adicionales ---
        st.markdown(f"##### AnÃ¡lisis Adicionales para: {selected_period_label_tab_vision}")
        st.markdown(f"<div class='dashboard-subtext' style='margin-bottom:1rem;'>{subtitle_period_string_tab_vision}</div>", unsafe_allow_html=True)

        # col_acq, col_geo = st.columns(2) # Eliminado para disposiciÃ³n vertical

        # GrÃ¡fico de Canal de AdquisiciÃ³n
        st.markdown("###### ğŸ“£ Canales de SesiÃ³n en GA Orders (PerÃ­odo Global)")
        
        # Asegurarse que el dataframe base no estÃ¡ vacÃ­o
        if df_ga_orders_filtered.empty:
            st.caption("No hay datos en GA Orders para el perÃ­odo global seleccionado.")
        elif 'Session_primary_channel_group' not in df_ga_orders_filtered.columns:
            st.caption("La columna 'Session_primary_channel_group' no existe en los datos de GA Orders.")
        elif df_ga_orders_filtered['Session_primary_channel_group'].isnull().all():
            st.caption("La columna 'Session_primary_channel_group' en GA Orders estÃ¡ completamente vacÃ­a (todos los valores son nulos) para el perÃ­odo seleccionado.")
        else:
            # Contar la frecuencia de cada canal en el perÃ­odo filtrado globalmente
            ga_channel_counts_in_period = df_ga_orders_filtered['Session_primary_channel_group'].value_counts().reset_index()
            ga_channel_counts_in_period.columns = ['Canal de SesiÃ³n (GA)', 'Conteo de Sesiones con TransacciÃ³n']
            
            # Filtrar filas donde el canal es nulo (si alguna quedara despuÃ©s del value_counts)
            ga_channel_counts_in_period = ga_channel_counts_in_period.dropna(subset=['Canal de SesiÃ³n (GA)'])

            if not ga_channel_counts_in_period.empty:
                fig_ga_channel_title = (
                    f"DistribuciÃ³n de Canales de SesiÃ³n (GA Orders)<br>"
                    f"<sub style='font-size:0.75em;'>PerÃ­odo Global: {start_date.strftime('%d %b %Y')} - {end_date.strftime('%d %b %Y')}. Fuente: `GA_ORDERS.csv`, columna `Session_primary_channel_group`.</sub>"
                )
                fig_ga_channels = px.bar(
                    ga_channel_counts_in_period, 
                    x='Canal de SesiÃ³n (GA)', 
                    y='Conteo de Sesiones con TransacciÃ³n', 
                    title=fig_ga_channel_title,
                    text='Conteo de Sesiones con TransacciÃ³n'
                )
                fig_ga_channels.update_traces(textposition='outside')
                fig_ga_channels.update_layout(
                    title_font_size=15, 
                    margin=dict(t=70, b=20, l=20, r=20),
                    height=400,
                    xaxis_title="Canal de SesiÃ³n (GA)",
                    yaxis_title="Conteo de Sesiones con TransacciÃ³n"
                )
                safe_plotly_chart(fig_ga_channels)
            else:
                st.caption(f"No se encontraron datos de 'Session_primary_channel_group' vÃ¡lidos en GA Orders para el perÃ­odo global seleccionado: {start_date.strftime('%d %b %Y')} - {end_date.strftime('%d %b %Y')}.")

        # GrÃ¡fico de GeolocalizaciÃ³n
        
        # 1. Mapa de Estados Unidos
        st.markdown("###### Mapa de Pedidos en Estados Unidos (por Estado)")
        df_us_items = df_items_for_tab_vision[df_items_for_tab_vision['SHIPPING_COUNTRY'].isin(['United States', 'US', 'USA'])] 
        
        if not df_us_items.empty and 'SHIPPING_STATE' in df_us_items.columns and df_us_items['SHIPPING_STATE'].notna().any():
            us_state_orders = df_us_items.groupby('SHIPPING_STATE')['ORDER_GID'].nunique().reset_index()
            us_state_orders.columns = ['Estado', 'NÃºmero de Pedidos'] # 'Estado' serÃ¡ usado para locations
            
            if 'SHIPPING_CITY' in df_us_items.columns:
                top_cities_per_state_list = []
                for state_name, group in df_us_items.groupby('SHIPPING_STATE'): # Usar SHIPPING_STATE
                    top_3_cities = group['SHIPPING_CITY'].value_counts().nlargest(3).index.tolist()
                    top_cities_str = ", ".join(top_3_cities)
                    top_cities_per_state_list.append({'Estado': state_name, 'Top Ciudades': top_cities_str})
                
                if top_cities_per_state_list:
                    top_cities_df = pd.DataFrame(top_cities_per_state_list)
                    us_state_orders = pd.merge(us_state_orders, top_cities_df, on='Estado', how='left')
                    us_state_orders['Top Ciudades'].fillna('N/A', inplace=True)
                else:
                    us_state_orders['Top Ciudades'] = 'N/A' 
            else:
                 us_state_orders['Top Ciudades'] = 'N/A'


            fig_us_map_title = (
                f"Mapa de Pedidos en EEUU por Estado<br>"
                f"<sub style='font-size:0.75em;'>PerÃ­odo: {selected_period_label_tab_vision}</sub>"
            )
            try:
                fig_us_map = px.choropleth(us_state_orders,
                                           locations='Estado', # Esta columna ahora viene de SHIPPING_STATE
                                           locationmode='USA-states',
                                           color='NÃºmero de Pedidos',
                                           scope='usa',
                                           hover_name='Estado',
                                           custom_data=['Top Ciudades'] if 'Top Ciudades' in us_state_orders else None,
                                           color_continuous_scale="Blues",
                                           title=fig_us_map_title)
                if 'Top Ciudades' in us_state_orders:
                     fig_us_map.update_traces(hovertemplate="<b>%{hovertext}</b><br>Pedidos: %{z}<br>Top Ciudades: %{customdata[0]}<extra></extra>")
                else:
                     fig_us_map.update_traces(hovertemplate="<b>%{hovertext}</b><br>Pedidos: %{z}<extra></extra>")

                fig_us_map.update_layout(title_font_size=15, margin=dict(t=60, b=0, l=0, r=0), height=450, geo=dict(bgcolor='rgba(0,0,0,0)'))
                safe_plotly_chart(fig_us_map)
            except Exception as e_us_map:
                st.warning(f"No se pudo generar el mapa de EEUU. Error: {e_us_map}")
                st.caption("Verifica que la columna 'SHIPPING_STATE' contenga nombres/abreviaturas de estados de EEUU vÃ¡lidos.")
        else:
            st.caption("No hay suficientes datos de pedidos en EEUU (o falta la columna 'SHIPPING_STATE') para generar el mapa de estados.")

        st.markdown("<br>", unsafe_allow_html=True)

        # 2. GrÃ¡fico de Barras por PaÃ­s (Global)
        st.markdown("###### Pedidos Globales por PaÃ­s")
        if 'SHIPPING_COUNTRY' in df_items_for_tab_vision.columns and not df_items_for_tab_vision['SHIPPING_COUNTRY'].isnull().all():
            all_country_orders = df_items_for_tab_vision.groupby('SHIPPING_COUNTRY')['ORDER_GID'].nunique().reset_index()
            all_country_orders.columns = ['PaÃ­s', 'NÃºmero de Pedidos']
            all_country_orders = all_country_orders.sort_values('NÃºmero de Pedidos', ascending=False).head(15) 

            if not all_country_orders.empty:
                fig_country_bar_title = (
                    f"Top 15 PaÃ­ses por NÃºmero de Pedidos<br>"
                    f"<sub style='font-size:0.75em;'>PerÃ­odo: {selected_period_label_tab_vision}</sub>"
                )
                fig_country_bar = px.bar(all_country_orders, x='PaÃ­s', y='NÃºmero de Pedidos', title=fig_country_bar_title)
                fig_country_bar.update_layout(title_font_size=15, margin=dict(t=60, b=20, l=20, r=20), height=400)
                safe_plotly_chart(fig_country_bar)
            else:
                st.caption("No hay datos de pedidos por paÃ­s para el grÃ¡fico de barras.")
        else:
            st.caption("La columna 'SHIPPING_COUNTRY' no estÃ¡ disponible para el grÃ¡fico de barras por paÃ­s.")


        # 3. Opcional: Top Ciudades en EEUU (GrÃ¡fico de Barras)
        st.markdown("###### Top Ciudades en Estados Unidos por Pedidos")
        if not df_us_items.empty and 'SHIPPING_CITY' in df_us_items.columns and df_us_items['SHIPPING_CITY'].notna().any() and 'SHIPPING_STATE' in df_us_items.columns:
            us_city_orders = df_us_items.groupby(['SHIPPING_STATE', 'SHIPPING_CITY'])['ORDER_GID'].nunique().reset_index(name='NÃºmero de Pedidos') # Usar SHIPPING_STATE
            us_city_orders['Lugar'] = us_city_orders['SHIPPING_CITY'] + ", " + us_city_orders['SHIPPING_STATE'] # Usar SHIPPING_STATE
            top_us_cities = us_city_orders.sort_values('NÃºmero de Pedidos', ascending=False).head(15)

            if not top_us_cities.empty:
                fig_us_city_title = (
                    f"Top 15 Ciudades en EEUU por Pedidos<br>"
                    f"<sub style='font-size:0.75em;'>PerÃ­odo: {selected_period_label_tab_vision}</sub>"
                )
                fig_us_city_bar = px.bar(top_us_cities, x='Lugar', y='NÃºmero de Pedidos', title=fig_us_city_title)
                fig_us_city_bar.update_layout(title_font_size=15, margin=dict(t=60, b=20, l=20, r=20), height=400)
                safe_plotly_chart(fig_us_city_bar)
            else:
                st.caption("No hay datos de pedidos por ciudad en EEUU para mostrar.")
        else:
            st.caption("No hay suficientes datos de ciudades/estados en EEUU para el grÃ¡fico de barras.")


    else: # df_items_for_tab_vision is empty or dates are not valid
        st.info(f"No hay datos de Ã³rdenes para el perÃ­odo seleccionado: '{selected_period_label_tab_vision}'. Por favor, ajusta la selecciÃ³n de perÃ­odo o el filtro global de fechas si aplica.")

# Tab 2: Frecuencia y Recurrencia de Compra
with tab_frecuencia:
    st.markdown("### ğŸ”„ Frecuencia y Recurrencia de Compra")
    st.markdown("<div class='dashboard-subtext'>AnÃ¡lisis de la frecuencia con la que los clientes compran y cuÃ¡nto tiempo pasa entre sus compras, basado en el perÃ­odo seleccionado en el filtro global de fechas.</div>", unsafe_allow_html=True)

    if not df_items_filtered.empty:
        customer_orders_freq = df_items_filtered.groupby('USER_EMAIL')['ORDER_GID'].nunique().reset_index(name='NUM_ORDERS')
        
        st.markdown("#### MÃ©tricas Clave de Frecuencia y Recurrencia")
        col_freq1, col_freq2, col_freq3 = st.columns(3)

        with col_freq1:
            avg_orders_per_customer = customer_orders_freq['NUM_ORDERS'].mean()
            st.metric("ğŸ“¦ Pedidos Promedio por Cliente", 
                      f"{avg_orders_per_customer:.2f}" if pd.notna(avg_orders_per_customer) else "N/A", 
                      help="Calculado como el nÃºmero total de pedidos Ãºnicos dividido por el nÃºmero total de clientes Ãºnicos (`USER_EMAIL`) que realizaron compras. Todo dentro del perÃ­odo global seleccionado y basado en datos de `SHOPIFY_ORDERS_LINEITEMS.csv`.")

        df_multi_orders_freq = pd.DataFrame() # Initialize df_multi_orders_freq
        with col_freq2:
            multi_order_customers_emails = customer_orders_freq[customer_orders_freq['NUM_ORDERS'] > 1]['USER_EMAIL']
            if not multi_order_customers_emails.empty:
                df_multi_orders_freq = df_items_filtered[df_items_filtered['USER_EMAIL'].isin(multi_order_customers_emails)].copy() 
                df_multi_orders_freq.sort_values(['USER_EMAIL', 'ORDER_CREATE_DATE'], inplace=True)
                df_multi_orders_freq['TIME_DIFF'] = df_multi_orders_freq.groupby('USER_EMAIL')['ORDER_CREATE_DATE'].diff().dt.days
                avg_time_between_purchases = df_multi_orders_freq['TIME_DIFF'].mean() 
                st.metric("â±ï¸ Tiempo Promedio entre Compras", 
                          f"{avg_time_between_purchases:.1f} dÃ­as" if pd.notna(avg_time_between_purchases) else "N/A", 
                          help="Promedio de dÃ­as transcurridos entre compras consecutivas. Se calcula solo para clientes que han realizado mÃ¡s de un pedido dentro del perÃ­odo global seleccionado. Basado en `SHOPIFY_ORDERS_LINEITEMS.csv`.")
            else:
                st.metric("â±ï¸ Tiempo Promedio entre Compras", "N/A", help="No hay suficientes clientes con mÃºltiples pedidos en el perÃ­odo para calcular. Se requiere mÃ¡s de un pedido por cliente en el perÃ­odo global seleccionado.")
        
        with col_freq3:
            recurrent_customer_count_freq = len(multi_order_customers_emails)
            total_customer_count_freq = customer_orders_freq['USER_EMAIL'].nunique()
            if total_customer_count_freq > 0:
                percentage_recurrent_freq = (recurrent_customer_count_freq / total_customer_count_freq) * 100
                st.metric("ğŸ” % Clientes Recurrentes", 
                          f"{percentage_recurrent_freq:.1f}%", 
                          help="Porcentaje de clientes Ãºnicos (`USER_EMAIL`) que realizaron mÃ¡s de un pedido dentro del perÃ­odo global seleccionado, sobre el total de clientes Ãºnicos en ese mismo perÃ­odo. Basado en `SHOPIFY_ORDERS_LINEITEMS.csv`.")
            else:
                st.metric("ğŸ” % Clientes Recurrentes", "N/A", help="No hay clientes en el perÃ­odo seleccionado.")
        
        st.markdown("---")
        st.markdown("#### ğŸ“Š Distribuciones de Frecuencia y Recurrencia")
        
        # GrÃ¡fico 1: DistribuciÃ³n del NÂº de Pedidos por Cliente
        if not customer_orders_freq.empty:
            # Definir bins y etiquetas para agrupar el nÃºmero de pedidos
            bins_num_orders = [0, 1, 2, 3, 5, 10, float('inf')]
            labels_num_orders = ['1 Pedido', '2 Pedidos', '3 Pedidos', '4-5 Pedidos', '6-10 Pedidos', '11+ Pedidos']
            
            # Crear una nueva columna con las categorÃ­as de pedidos
            customer_orders_freq['PEDIDOS_AGRUPADOS'] = pd.cut(
                customer_orders_freq['NUM_ORDERS'],
                bins=bins_num_orders,
                labels=labels_num_orders,
                right=True,
                include_lowest=True # Asegura que el 0 (si existiera) se incluya en el primer bin si el bin empieza en 0.
                                     # En este caso, NUM_ORDERS empieza en 1, por lo que [0,1] captura el 1.
            )
            
            # Contar clientes por categorÃ­a agrupada
            order_counts_grouped = customer_orders_freq['PEDIDOS_AGRUPADOS'].value_counts().reset_index()
            order_counts_grouped.columns = ['Grupo de Pedidos', 'NÃºmero de Clientes']
            
            # Asegurar el orden correcto de las categorÃ­as para el grÃ¡fico
            order_counts_grouped['Grupo de Pedidos'] = pd.Categorical(
                order_counts_grouped['Grupo de Pedidos'],
                categories=labels_num_orders,
                ordered=True
            )
            order_counts_grouped = order_counts_grouped.sort_values('Grupo de Pedidos')

            fig_dist_num_orders_title = (
                "DistribuciÃ³n del NÂº de Pedidos por Cliente (Agrupado)<br>"
                "<sub>CuÃ¡ntos clientes (`USER_EMAIL`) caen en rangos de cantidad de pedidos realizados en el perÃ­odo global. Fuente: `SHOPIFY_ORDERS_LINEITEMS.csv`.</sub>"
            )
            fig_dist_num_orders = px.bar( # Cambiado a px.bar
                order_counts_grouped, 
                x="Grupo de Pedidos", 
                y="NÃºmero de Clientes",
                title=fig_dist_num_orders_title
            )
            fig_dist_num_orders.update_layout(title_font_size=15, height=350, xaxis_title="Grupo de Cantidad de Pedidos")
            safe_plotly_chart(fig_dist_num_orders)
        else:
            st.caption("No hay datos para la distribuciÃ³n del nÃºmero de pedidos.")

        # GrÃ¡fico 2: DistribuciÃ³n del Tiempo Entre Compras
        if not df_multi_orders_freq.empty and 'TIME_DIFF' in df_multi_orders_freq.columns and df_multi_orders_freq['TIME_DIFF'].notna().any():
            fig_dist_time_between_title = (
                "DistribuciÃ³n del Tiempo Entre Compras (DÃ­as)<br>"
                "<sub>Frecuencia de dÃ­as entre compras consecutivas para clientes con >1 pedido en perÃ­odo global. Fuente: `SHOPIFY_ORDERS_LINEITEMS.csv`.</sub>"
            )
            fig_dist_time_between = px.histogram(df_multi_orders_freq.dropna(subset=['TIME_DIFF']), x="TIME_DIFF",
                                                 title=fig_dist_time_between_title,
                                                 labels={"TIME_DIFF": "DÃ­as entre Compras Consecutivas"})
            fig_dist_time_between.update_layout(bargap=0.1, title_font_size=15, height=350)
            safe_plotly_chart(fig_dist_time_between)
        else:
            st.caption("No hay datos suficientes para la distribuciÃ³n del tiempo entre compras.")
        
        st.markdown("#### ğŸ“ˆ SegmentaciÃ³n por Frecuencia de Compra")
        if not customer_orders_freq.empty:
            bins = [0, 1, 3, 5, float('inf')]
            labels = ['1 Pedido (Comprador Ãšnico)', '2-3 Pedidos (Ocasional)', '4-5 Pedidos (Frecuente)', '6+ Pedidos (Leal)']
            customer_orders_freq['SEGMENTO_FRECUENCIA'] = pd.cut(customer_orders_freq['NUM_ORDERS'], bins=bins, labels=labels, right=True)
            
            segment_counts = customer_orders_freq['SEGMENTO_FRECUENCIA'].value_counts().reset_index()
            segment_counts.columns = ['Segmento por Frecuencia', 'NÃºmero de Clientes']
            segment_counts = segment_counts.sort_values(by='Segmento por Frecuencia', key=lambda x: x.map({label: i for i, label in enumerate(labels)}))


            fig_segment_freq_title = (
                "SegmentaciÃ³n de Clientes por Frecuencia de Pedidos<br>"
                "<sub>Clientes en segmentos (Comprador Ãšnico, Ocasional, etc.) segÃºn nÂº de pedidos en perÃ­odo global. Fuente: `SHOPIFY_ORDERS_LINEITEMS.csv`.</sub>"
            )
            fig_segment_freq = px.bar(segment_counts, x="Segmento por Frecuencia", y="NÃºmero de Clientes",
                                      title=fig_segment_freq_title)
            fig_segment_freq.update_layout(title_font_size=15, height=400)
            safe_plotly_chart(fig_segment_freq)
        else:
            st.caption("No hay datos para segmentar por frecuencia.")


        st.markdown("---")
        st.markdown("#### ğŸ“… AnÃ¡lisis de Cohortes (RetenciÃ³n Mensual)")
        st.markdown("""
        <div class='dashboard-subtext' style='font-size:0.88rem; line-height:1.4;'>
        Este anÃ¡lisis muestra quÃ© porcentaje de clientes que hicieron su <i>primera compra global</i> en un mes especÃ­fico ('cohorte')
        volvieron a comprar en los meses siguientes. La cohorte se define usando todos los datos histÃ³ricos de Ã³rdenes, 
        y luego se observa su actividad de compra (retenciÃ³n) dentro del <b>perÃ­odo actualmente filtrado en el dashboard</b>.
        </div>
        """, unsafe_allow_html=True)
        
        # Se utiliza df_items (completo) para definir la COHORTE (mes de primera compra global)
        df_items_copy_cohort = df_items.copy() 
        df_items_copy_cohort['ORDER_MONTH'] = df_items_copy_cohort['ORDER_CREATE_DATE'].dt.to_period('M')
        df_items_copy_cohort['COHORT'] = df_items_copy_cohort.groupby('USER_EMAIL')['ORDER_CREATE_DATE'].transform('min').dt.to_period('M')
        
        # Ahora, para ver la actividad de estas cohortes, filtramos por el df_items_filtered (perÃ­odo del dashboard)
        # y traemos la informaciÃ³n de COHORTE original.
        df_cohort_data_activity_in_period = pd.merge(
            df_items_filtered.copy(), # Actividad en el perÃ­odo filtrado
            df_items_copy_cohort[['USER_EMAIL', 'COHORT']].drop_duplicates(subset=['USER_EMAIL']), # Cohorte global del cliente
            on='USER_EMAIL',
            how='left' # Nos quedamos solo con clientes activos en el perÃ­odo filtrado
        )
        # Necesitamos el mes de la orden tambiÃ©n para la actividad en el perÃ­odo
        df_cohort_data_activity_in_period['ORDER_MONTH_ACTIVITY'] = df_cohort_data_activity_in_period['ORDER_CREATE_DATE'].dt.to_period('M')

        if not df_cohort_data_activity_in_period.empty and 'COHORT' in df_cohort_data_activity_in_period.columns:
            df_cohort_counts = df_cohort_data_activity_in_period.groupby(['COHORT', 'ORDER_MONTH_ACTIVITY']) \
                                            .agg(n_customers=('USER_EMAIL', 'nunique')) \
                                            .reset_index(drop=False)
            
            if not df_cohort_counts.empty:
                df_cohort_counts['PERIOD_NUMBER'] = (df_cohort_counts['ORDER_MONTH_ACTIVITY'] - df_cohort_counts['COHORT']).apply(lambda x: x.n if pd.notnull(x) else -1)
                # Filtrar periodos negativos que podrÃ­an surgir si la cohorte es posterior al mes de actividad (no deberÃ­a pasar con 'left' merge y transform)
                df_cohort_counts = df_cohort_counts[df_cohort_counts['PERIOD_NUMBER'] >= 0]

                cohort_pivot = df_cohort_counts.pivot_table(index='COHORT',
                                                            columns='PERIOD_NUMBER',
                                                            values='n_customers')
                if not cohort_pivot.empty:
                    # Cohort size es el nÃºmero de clientes Ãºnicos en la cohorte original (primera compra global)
                    cohort_size_df = df_items_copy_cohort.groupby('COHORT')['USER_EMAIL'].nunique().reset_index(name='TOTAL_CUSTOMERS_IN_COHORT')
                    cohort_pivot_with_size = cohort_pivot.reset_index().merge(cohort_size_df, on='COHORT', how='left').set_index('COHORT')
                    
                    cohort_matrix = cohort_pivot_with_size.iloc[:, :-1].divide(cohort_pivot_with_size['TOTAL_CUSTOMERS_IN_COHORT'], axis=0)
                    
                    # Preparar datos para el grÃ¡fico de lÃ­neas de retenciÃ³n promedio
                    if not cohort_matrix.empty:
                        # Calcular la retenciÃ³n promedio por cada perÃ­odo
                        avg_retention_curve = cohort_matrix.mean(axis=0) # Promedio por columna (PERIOD_NUMBER)
                        avg_retention_curve.index = avg_retention_curve.index.astype(int) # Asegurar que el Ã­ndice es entero
                        avg_retention_curve = avg_retention_curve.sort_index()
                        avg_retention_df = avg_retention_curve.reset_index()
                        avg_retention_df.columns = ['Meses Desde Primera Compra', 'Tasa de RetenciÃ³n Promedio']
                        
                        # Convertir tasa a porcentaje para visualizaciÃ³n
                        avg_retention_df['Tasa de RetenciÃ³n Promedio'] = avg_retention_df['Tasa de RetenciÃ³n Promedio'] * 100

                        # DescripciÃ³n detallada del grÃ¡fico
                        st.markdown("""
                        <div class='dashboard-subtext' style='font-size:0.88rem; line-height:1.4; margin-bottom:0.5rem;'>
                        Este grÃ¡fico ilustra la <b>Curva de RetenciÃ³n Promedio Global</b>. Representa el porcentaje promedio de clientes que realizan compras adicionales en los meses siguientes a su mes de primera compra (definido como 'Mes 0').
                        <ul>
                            <li>El <b>eje X</b> ('Meses Desde Primera Compra') indica el nÃºmero de meses transcurridos desde la primera compra del cliente.</li>
                            <li>El <b>eje Y</b> ('Tasa de RetenciÃ³n Promedio (%)') muestra el porcentaje de clientes, promediado entre todas las cohortes, que estuvieron activos (realizaron una compra) durante ese mes especÃ­fico posterior a su adquisiciÃ³n.</li>
                            <li>Este anÃ¡lisis considera la actividad de compra de las cohortes dentro del <b>perÃ­odo global filtrado</b> en el dashboard.</li>
                        </ul>
                        Una curva descendente es tÃ­pica, pero su pendiente y los puntos donde se estabiliza ofrecen informaciÃ³n clave sobre la lealtad del cliente a largo plazo.
                        </div>
                        """, unsafe_allow_html=True)

                        fig_avg_retention_title = "Curva de RetenciÃ³n Promedio Global" # TÃ­tulo simplificado
                        
                        fig_avg_retention = px.line(
                            avg_retention_df, 
                            x='Meses Desde Primera Compra', 
                            y='Tasa de RetenciÃ³n Promedio',
                            title=fig_avg_retention_title,
                            markers=True,
                            labels={'Tasa de RetenciÃ³n Promedio': 'Tasa de RetenciÃ³n Promedio (%)'}
                        )
                        fig_avg_retention.update_layout(
                            yaxis_ticksuffix="%",
                            xaxis_dtick=1 # Mostrar cada mes en el eje X
                        )
                        safe_plotly_chart(fig_avg_retention)
                    else:
                        st.info("No hay suficientes datos para generar la curva de retenciÃ³n promedio (matriz de cohortes vacÃ­a).")
                else:
                    st.info("No hay suficientes datos para el anÃ¡lisis de cohortes (pivot vacÃ­o) con los filtros actuales.")
            else:
                st.info("No hay suficientes datos para el anÃ¡lisis de cohortes (counts vacÃ­os) con los filtros actuales.")
        else:
            st.info("No hay datos de Ã³rdenes o cohortes para el perÃ­odo seleccionado (verifique `df_cohort_data_activity_in_period`).")
            if "AnÃ¡lisis de Cohortes (datos insuficientes o configuraciÃ³n compleja)" not in missing_data_points:
                missing_data_points.append("AnÃ¡lisis de Cohortes (datos insuficientes o configuraciÃ³n compleja)")
    else:
        st.info("No hay Ã³rdenes en el perÃ­odo seleccionado globalmente para analizar frecuencia y recurrencia.")

# Tab 3: Valor del Cliente
with tab_valor:
    st.markdown("### ğŸ’° Valor del Cliente (LTV)")
    st.markdown("<div class='dashboard-subtext'>Entendiendo el valor que los clientes aportan a lo largo del tiempo, basado en el perÃ­odo seleccionado en el filtro global de fechas.</div>", unsafe_allow_html=True)

    if not df_items_filtered.empty:
        ltv_data = df_items_filtered.groupby('USER_EMAIL')['ORDER_TOTAL_PRICE'].sum().reset_index(name='LTV')
        
        st.markdown("#### ğŸ’¸ LTV Promedio General (en perÃ­odo)")
        avg_ltv = ltv_data['LTV'].mean()
        st.metric("LTV Promedio (en perÃ­odo)", f"${avg_ltv:,.2f}" if pd.notna(avg_ltv) else "N/A", 
                  help="Valor de Vida del Cliente promedio. Se calcula sumando el `ORDER_TOTAL_PRICE` de todos los pedidos para cada cliente (`USER_EMAIL`) dentro del perÃ­odo global seleccionado, y luego promediando estas sumas entre todos los clientes. Fuente: `SHOPIFY_ORDERS_LINEITEMS.csv`.")

        st.markdown("#### ğŸ“Š LTV Promedio por Canal de AdquisiciÃ³n (Primer Pedido)")
        if not df_ga_orders.empty:
            first_order_info_valor = df_items.loc[df_items.groupby('USER_EMAIL')['ORDER_CREATE_DATE'].idxmin()]
            merged_first_orders_valor = pd.merge(first_order_info_valor, df_ga_orders, 
                                           left_on='ORDER_GID_STR', right_on='Transaction_ID', 
                                           how='left')
            
            if not merged_first_orders_valor.empty and 'Session_primary_channel_group' in merged_first_orders_valor.columns:
                ltv_con_canal_adq = pd.merge(ltv_data, 
                                             merged_first_orders_valor[['USER_EMAIL', 'Session_primary_channel_group']].drop_duplicates(subset=['USER_EMAIL']),
                                             on='USER_EMAIL',
                                             how='left')
                
                if not ltv_con_canal_adq.empty and 'Session_primary_channel_group' in ltv_con_canal_adq.columns:
                    ltv_by_channel = ltv_con_canal_adq.groupby('Session_primary_channel_group')['LTV'].mean().reset_index()
                    ltv_by_channel = ltv_by_channel.sort_values('LTV', ascending=False)
                    fig_ltv_channel_title = (
                        "LTV Promedio por Canal de AdquisiciÃ³n del Cliente (1Âª Compra Global)<br>"
                        "<sub>LTV (gasto total en perÃ­odo global) promediado por canal de 1Âª compra global. Canales de `GA_ORDERS.csv`, LTV de `SHOPIFY_ORDERS_LINEITEMS.csv`.</sub>"
                    )
                    fig = px.bar(ltv_by_channel, x='Session_primary_channel_group', y='LTV', 
                                 title=fig_ltv_channel_title,
                                 labels={'Session_primary_channel_group': 'Canal de AdquisiciÃ³n', 'LTV': 'LTV Promedio ($)'})
                    safe_plotly_chart(fig)
                else:
                    st.info("No se pudo calcular LTV por canal de adquisiciÃ³n (datos de canal o LTV insuficientes).")
            else:
                st.warning("No se pudo determinar el canal de adquisiciÃ³n para LTV. Verifica la uniÃ³n entre 'SHOPIFY_ORDERS_LINEITEMS' y 'GA_ORDERS'.")
                if "LTV por Canal de AdquisiciÃ³n (datos insuficientes o uniÃ³n fallida)" not in missing_data_points:
                    missing_data_points.append("LTV por Canal de AdquisiciÃ³n (datos insuficientes o uniÃ³n fallida)")
        else:
            st.info("Datos de GA Orders no disponibles para LTV por canal.")

        st.markdown("#### ğŸ† SegmentaciÃ³n de Clientes por Ranking de FacturaciÃ³n (en perÃ­odo)")
        if not ltv_data.empty:
            ltv_data_sorted = ltv_data.sort_values('LTV', ascending=False)
            # Asegurar que hay suficientes valores Ãºnicos para qcut, o usar rangos fijos si no.
            try:
                ltv_data_sorted['RANK'] = pd.qcut(ltv_data_sorted['LTV'], q=4, labels=["Bajo", "Medio-Bajo", "Medio-Alto", "Alto"], duplicates='drop')
            except ValueError: # Ocurre si no hay suficientes cuantiles distintos
                 ltv_data_sorted['RANK'] = pd.cut(ltv_data_sorted['LTV'], bins=4, labels=["Bajo", "Medio-Bajo", "Medio-Alto", "Alto"], duplicates='drop', include_lowest=True)


            segment_summary = ltv_data_sorted.groupby('RANK', observed=False).agg(
                num_customers=('USER_EMAIL', 'count'),
                total_revenue=('LTV', 'sum'),
                avg_revenue_per_customer=('LTV', 'mean')
            ).reset_index()
            st.write("SegmentaciÃ³n de Clientes por FacturaciÃ³n (LTV en perÃ­odo global):")
            st.dataframe(segment_summary)
            st.markdown("<div class='dashboard-subtext' style='font-size:0.8rem; text-align:center; margin-top:-5px;'>Los clientes se agrupan en cuatro categorÃ­as (Alto, Medio-Alto, Medio-Bajo, Bajo) segÃºn su gasto total (`LTV`) durante el perÃ­odo global seleccionado. LTV se calcula como la suma de `ORDER_TOTAL_PRICE` por cliente desde `SHOPIFY_ORDERS_LINEITEMS.csv`. La tabla muestra el nÃºmero de clientes, los ingresos totales y el ingreso promedio por cliente para cada segmento.</div>", unsafe_allow_html=True)
        else:
            st.info("No hay datos de LTV para segmentar clientes.")

        st.markdown("#### ğŸ’ LTV Promedio por Segmento de Frecuencia de Compra")
        # Reutilizar customer_orders_freq de la pestaÃ±a de Frecuencia (basado en df_items_filtered)
        if 'customer_orders_freq' not in locals(): # Asegurar que existe, si se accede a esta pestaÃ±a directamente
            if not df_items_filtered.empty:
                 customer_orders_freq = df_items_filtered.groupby('USER_EMAIL')['ORDER_GID'].nunique().reset_index(name='NUM_ORDERS')
            else:
                 customer_orders_freq = pd.DataFrame(columns=['USER_EMAIL', 'NUM_ORDERS'])

        if not customer_orders_freq.empty and not ltv_data.empty:
            # Definir segmentos de frecuencia (igual que en la pestaÃ±a de Frecuencia)
            bins_ltv_freq = [0, 1, 3, 5, float('inf')]
            labels_ltv_freq = ['1 Pedido (Comprador Ãšnico)', '2-3 Pedidos (Ocasional)', '4-5 Pedidos (Frecuente)', '6+ Pedidos (Leal)']
            
            # Crear copia para no afectar el DataFrame original usado en otra pestaÃ±a
            customer_orders_freq_copy = customer_orders_freq.copy()
            customer_orders_freq_copy['SEGMENTO_FRECUENCIA'] = pd.cut(customer_orders_freq_copy['NUM_ORDERS'], bins=bins_ltv_freq, labels=labels_ltv_freq, right=True)
            
            # Unir con datos de LTV
            ltv_con_segmento_frecuencia = pd.merge(ltv_data, customer_orders_freq_copy[['USER_EMAIL', 'SEGMENTO_FRECUENCIA']], on='USER_EMAIL', how='left')
            
            if not ltv_con_segmento_frecuencia.empty and 'SEGMENTO_FRECUENCIA' in ltv_con_segmento_frecuencia.columns and ltv_con_segmento_frecuencia['SEGMENTO_FRECUENCIA'].notna().any():
                avg_ltv_by_freq_segment = ltv_con_segmento_frecuencia.groupby('SEGMENTO_FRECUENCIA', observed=False)['LTV'].mean().reset_index()
                avg_ltv_by_freq_segment = avg_ltv_by_freq_segment.sort_values(by='SEGMENTO_FRECUENCIA', key=lambda x: x.map({label: i for i, label in enumerate(labels_ltv_freq)}))


                fig_ltv_by_freq_title = (
                    "LTV Promedio por Segmento de Frecuencia de Compra<br>"
                    "<sub>LTV promedio (gasto total en perÃ­odo global) por segmento de frecuencia de compra (NÂº pedidos en mismo perÃ­odo). Fuente: `SHOPIFY_ORDERS_LINEITEMS.csv`.</sub>"
                )
                fig_ltv_by_freq = px.bar(avg_ltv_by_freq_segment, x='SEGMENTO_FRECUENCIA', y='LTV',
                                         title=fig_ltv_by_freq_title,
                                         labels={'SEGMENTO_FRECUENCIA': 'Segmento por Frecuencia', 'LTV': 'LTV Promedio ($)'})
                fig_ltv_by_freq.update_layout(title_font_size=15, height=400)
                safe_plotly_chart(fig_ltv_by_freq)
            else:
                st.info("No se pudo calcular el LTV por segmento de frecuencia (datos insuficientes o segmentos no aplicables).")
        else:
            st.info("Datos de frecuencia de clientes o LTV no disponibles para este anÃ¡lisis.")


        st.markdown("#### ğŸ“ˆ Tendencias del AOV (Valor Promedio del Pedido)")
        if not df_items_filtered.empty and df_items_filtered['ORDER_GID'].nunique() > 0 : # Asegurarse que hay ordenes
            aov_trend = df_items_filtered.groupby(pd.Grouper(key='ORDER_CREATE_DATE', freq='M')).agg(
                total_revenue=('ORDER_TOTAL_PRICE', 'sum'),
                total_orders=('ORDER_GID', 'nunique')
            ).reset_index()
            # Evitar divisiÃ³n por cero
            aov_trend['AOV'] = np.where(aov_trend['total_orders'] > 0, aov_trend['total_revenue'] / aov_trend['total_orders'], np.nan)
            aov_trend = aov_trend.dropna(subset=['AOV']) 
            
            if not aov_trend.empty:
                fig_aov_title = (
                    "Tendencia Mensual del AOV (Valor Promedio del Pedido)<br>"
                    "<sub>AOV mensual = Ingresos totales del mes / NÂº de pedidos Ãºnicos del mes. PerÃ­odo global. Fuente: `SHOPIFY_ORDERS_LINEITEMS.csv`.</sub>"
                )
                fig = px.line(aov_trend, x='ORDER_CREATE_DATE', y='AOV', title=fig_aov_title)
                fig.update_xaxes(title_text='Mes')
                fig.update_yaxes(title_text='AOV ($)')
                safe_plotly_chart(fig)
            else:
                st.info("No hay datos suficientes para mostrar la tendencia del AOV.")
        else:
            st.info("No hay Ã³rdenes en el perÃ­odo seleccionado para calcular AOV.")
    else:
        st.info("No hay Ã³rdenes en el perÃ­odo seleccionado para analizar el valor del cliente.")


# Tab 4: Comportamiento de Compra
with tab_comportamiento:
    st.markdown("### ğŸ›’ Comportamiento de Compra")
    st.markdown("<div class='dashboard-subtext'>QuÃ© compran los clientes y cÃ³mo se relacionan los productos.</div>", unsafe_allow_html=True)

    if not df_items_filtered.empty:
        st.markdown("#### ğŸ›ï¸ Productos MÃ¡s Comprados por Clientes Recurrentes (en perÃ­odo)")
        customer_order_counts_period = df_items_filtered.groupby('USER_EMAIL')['ORDER_GID'].nunique()
        recurrent_customers_period = customer_order_counts_period[customer_order_counts_period > 1].index
        
        if not recurrent_customers_period.empty:
            df_recurrent_purchases = df_items_filtered[df_items_filtered['USER_EMAIL'].isin(recurrent_customers_period)]
            if not df_recurrent_purchases.empty:
                top_products_recurrent = df_recurrent_purchases.groupby('PRODUCT_NAME')['LINEITEM_QTY'].sum().nlargest(10).reset_index()
                fig_top_recurrent_title = (
                    "Top 10 Productos por Clientes Recurrentes (Cantidad Total de Unidades)<br>"
                    "<sub>Productos mÃ¡s comprados (suma de `LINEITEM_QTY`) por clientes con >1 pedido en perÃ­odo global. Fuente: `SHOPIFY_ORDERS_LINEITEMS.csv`.</sub>"
                )
                fig = px.bar(top_products_recurrent, x='PRODUCT_NAME', y='LINEITEM_QTY', 
                             title=fig_top_recurrent_title)
                safe_plotly_chart(fig)
            else:
                st.info("No hay compras de clientes recurrentes en el perÃ­odo seleccionado.")
        else:
            st.info("No hay clientes recurrentes en el perÃ­odo seleccionado para este anÃ¡lisis.")

        st.markdown("#### ğŸ”— Cross-sell y Bundles (Pares de Productos MÃ¡s Comunes en el Mismo Pedido)")
        if 'ORDER_GID' in df_items_filtered.columns and 'PRODUCT_NAME' in df_items_filtered.columns:
            from itertools import combinations
            order_item_counts = df_items_filtered.groupby('ORDER_GID')['PRODUCT_NAME'].nunique()
            multi_item_orders = order_item_counts[order_item_counts > 1].index
            
            if not multi_item_orders.empty:
                df_multi_item_orders = df_items_filtered[df_items_filtered['ORDER_GID'].isin(multi_item_orders)]
                
                frequent_pairs = {}
                for order_gid, group in df_multi_item_orders.groupby('ORDER_GID'):
                    products_in_order = sorted(list(set(group['PRODUCT_NAME']))) 
                    if len(products_in_order) >= 2:
                        for pair in combinations(products_in_order, 2):
                            frequent_pairs[pair] = frequent_pairs.get(pair, 0) + 1
                
                if frequent_pairs:
                    top_pairs_df = pd.DataFrame(list(frequent_pairs.items()), columns=['Product_Pair', 'Frequency'])
                    top_pairs_df = top_pairs_df.sort_values('Frequency', ascending=False).head(10)
                    top_pairs_df['Product_Pair_Display'] = top_pairs_df['Product_Pair'].apply(lambda x: f"{x[0]} & {x[1]}")
                    
                    fig_pairs_title = (
                        "Top 10 Pares de Productos Comprados Juntos (Frecuencia en Pedidos)<br>"
                        "<sub>Pares de productos distintos que mÃ¡s frecuentemente aparecen juntos en el mismo pedido (`ORDER_GID`) en perÃ­odo global. Fuente: `SHOPIFY_ORDERS_LINEITEMS.csv`.</sub>"
                    )
                    fig_pairs = px.bar(top_pairs_df, x='Product_Pair_Display', y='Frequency',
                                     title=fig_pairs_title)
                    fig_pairs.update_xaxes(title_text="Par de Productos")
                    safe_plotly_chart(fig_pairs)
                else:
                    st.info("No se encontraron pares de productos comprados juntos con frecuencia en el perÃ­odo.")
            else:
                st.info("No hay pedidos con mÃºltiples productos diferentes en el perÃ­odo seleccionado para anÃ¡lisis de cross-sell.")
        else:
            if "Cross-sell y Bundles (columnas 'ORDER_GID' o 'PRODUCT_NAME' faltantes, o anÃ¡lisis complejo)" not in missing_data_points:
                missing_data_points.append("Cross-sell y Bundles (columnas 'ORDER_GID' o 'PRODUCT_NAME' faltantes, o anÃ¡lisis complejo)")
            st.warning("Datos insuficientes para anÃ¡lisis de cross-sell.")

        st.markdown("#### â˜€ï¸ Estacionalidad de Compras")
        # Create a copy to avoid SettingWithCopyWarning
        df_items_filtered_seasonal = df_items_filtered.copy()
        df_items_filtered_seasonal['MONTH'] = df_items_filtered_seasonal['ORDER_CREATE_DATE'].dt.strftime('%B')
        df_items_filtered_seasonal['DAY_OF_WEEK'] = df_items_filtered_seasonal['ORDER_CREATE_DATE'].dt.day_name()
        
        months_order = ["January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December"]
        days_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]

        sales_by_month = df_items_filtered_seasonal.groupby('MONTH')['ORDER_TOTAL_PRICE'].sum().reindex(months_order).reset_index()
        sales_by_day = df_items_filtered_seasonal.groupby('DAY_OF_WEEK')['ORDER_TOTAL_PRICE'].sum().reindex(days_order).reset_index()

        col1, col2 = st.columns(2)
        with col1:
            if not sales_by_month.empty:
                fig_month_title = (
                    "Estacionalidad: Ingresos Totales por Mes<br>"
                    "<sub>Suma de `ORDER_TOTAL_PRICE` por mes, en perÃ­odo global. Fuente: `SHOPIFY_ORDERS_LINEITEMS.csv`.</sub>"
                )
                fig_month = px.bar(sales_by_month, x='MONTH', y='ORDER_TOTAL_PRICE', title=fig_month_title)
                safe_plotly_chart(fig_month)
            else:
                st.info("No hay datos de ventas mensuales en el perÃ­odo.")
        with col2:
            if not sales_by_day.empty:
                fig_day_title = (
                    "Estacionalidad: Ingresos Totales por DÃ­a de la Semana<br>"
                    "<sub>Suma de `ORDER_TOTAL_PRICE` por dÃ­a de la semana, en perÃ­odo global. Fuente: `SHOPIFY_ORDERS_LINEITEMS.csv`.</sub>"
                )
                fig_day = px.bar(sales_by_day, x='DAY_OF_WEEK', y='ORDER_TOTAL_PRICE', title=fig_day_title)
                safe_plotly_chart(fig_day)
            else:
                st.info("No hay datos de ventas por dÃ­a de la semana en el perÃ­odo.")
        if "Estacionalidad por fechas especiales (requiere configuraciÃ³n manual de fechas)" not in missing_data_points:
            missing_data_points.append("Estacionalidad por fechas especiales (requiere configuraciÃ³n manual de fechas)")
    else:
        st.info("No hay Ã³rdenes en el perÃ­odo seleccionado para analizar el comportamiento de compra.")


# Tab 5: Traffic Analytics
with tab_trafico:
    st.markdown("### ğŸ“ˆ Traffic Analytics")
    st.markdown("<div class='dashboard-subtext'>AnÃ¡lisis del trÃ¡fico web y su efectividad.</div>", unsafe_allow_html=True)

    if not df_sessions_filtered.empty:
        st.markdown("#### ğŸ“‰ Tasa de Rebote (Bounce Rate)")
        if 'BOUNCE_RATE' in df_sessions_filtered.columns:
            avg_bounce_rate = df_sessions_filtered['BOUNCE_RATE'].mean() * 100
            st.metric("Tasa de Rebote Promedio", f"{avg_bounce_rate:.2f}%" if pd.notna(avg_bounce_rate) else "N/A", 
                      help="Porcentaje promedio de sesiones que terminaron despuÃ©s de ver una sola pÃ¡gina (rebote). Se calcula como la media de la columna `BOUNCE_RATE` (donde 1 es un rebote) del archivo `GA_SESSIONS.csv` para el perÃ­odo global seleccionado, multiplicado por 100.")
        else:
            st.warning("Columna 'BOUNCE_RATE' no encontrada en `GA_SESSIONS.csv`. No se puede calcular la tasa de rebote.")

        st.markdown("#### â³ DuraciÃ³n Promedio de SesiÃ³n")
        if 'AVG_SESSION_DURATION' in df_sessions_filtered.columns:
            avg_duration = df_sessions_filtered['AVG_SESSION_DURATION'].mean()
            st.metric("DuraciÃ³n Promedio de SesiÃ³n (segundos)", f"{avg_duration:.2f}s" if pd.notna(avg_duration) else "N/A", 
                      help="Tiempo promedio (en segundos) que los usuarios pasan en el sitio por sesiÃ³n. Se calcula como la media de la columna `AVG_SESSION_DURATION` del archivo `GA_SESSIONS.csv` para el perÃ­odo global seleccionado.")
        else:
            st.warning("Columna 'AVG_SESSION_DURATION' no encontrada en `GA_SESSIONS.csv`. No se puede calcular la duraciÃ³n promedio.")
    else:
        st.info("No hay datos de sesiones en el perÃ­odo seleccionado.")

    if not df_ads_filtered.empty:
        st.markdown("#### ğŸ‘‰ CTR (Click-Through Rate) Promedio de Anuncios")
        if 'Ads_CTR' in df_ads_filtered.columns:
            avg_ctr = df_ads_filtered['Ads_CTR'].mean() * 100
            st.metric("CTR Promedio de Anuncios", f"{avg_ctr:.2f}%" if pd.notna(avg_ctr) else "N/A", 
                      help="Tasa de Clics (Click-Through Rate) promedio de las campaÃ±as de anuncios. Se calcula como la media de la columna `Ads_CTR` (definida como Clics / Impresiones) del archivo `GA_ADS_CAMPAIGNS.csv` para el perÃ­odo global seleccionado, multiplicado por 100 para expresar como porcentaje.")
        else:
            st.warning("Columna 'Ads_CTR' no encontrada en `GA_ADS_CAMPAIGNS.csv`.")
            if "CTR de Anuncios (columna 'Ads_CTR' no encontrada)" not in missing_data_points:
                missing_data_points.append("CTR de Anuncios (columna 'Ads_CTR' no encontrada)")
    else:
        st.info("No hay datos de anuncios en el perÃ­odo seleccionado para CTR.")

    st.markdown("#### ğŸ›’ Tasa de Abandono de Carrito (CAR)")
    st.warning("El cÃ¡lculo de la Tasa de Abandono de Carrito (CAR) requiere datos especÃ­ficos sobre eventos de 'aÃ±adir al carrito' y 'compras completadas' que no estÃ¡n disponibles o no se han configurado para su cÃ¡lculo con los CSVs actuales. Formula: (Carritos Creados - Transacciones) / Carritos Creados.")
    st.markdown("<div class='dashboard-subtext' style='font-size:0.8rem; text-align:center; margin-top:5px;'>Idealmente, se usarÃ­an datos de `ADD_TO_CART_EVENTS` y `PURCHASE_EVENTS` del dataset de sesiones o similar.</div>", unsafe_allow_html=True)

# Tab 6: Costo de AdquisiciÃ³n
with tab_costo:
    st.markdown("### ğŸ’¸ Costo de AdquisiciÃ³n")
    st.markdown("<div class='dashboard-subtext'>AnÃ¡lisis de cuÃ¡nto cuesta adquirir nuevos clientes.</div>", unsafe_allow_html=True)

    if not df_ads_filtered.empty:
        st.markdown("#### ğŸ“Š CAC (Costo de AdquisiciÃ³n de Cliente) por Canal (Curva de EvoluciÃ³n)")
        if 'Ads_cost' in df_ads_filtered.columns and 'Total_users' in df_ads_filtered.columns and 'Primary_channel_group' in df_ads_filtered.columns:
            df_ads_filtered_cac = df_ads_filtered.copy()
            # Asegurar que Total_users no es cero para evitar divisiÃ³n por cero
            df_ads_filtered_cac['CAC'] = np.where(df_ads_filtered_cac['Total_users'] > 0, df_ads_filtered_cac['Ads_cost'] / df_ads_filtered_cac['Total_users'], np.nan)
            df_ads_filtered_cac['CAC'] = df_ads_filtered_cac['CAC'].replace([np.inf, -np.inf], np.nan) 

            cac_by_channel_time = df_ads_filtered_cac.groupby([pd.Grouper(key='Date', freq='M'), 'Primary_channel_group'])['CAC'].mean().reset_index()
            cac_by_channel_time = cac_by_channel_time.dropna(subset=['CAC'])

            if not cac_by_channel_time.empty:
                fig_cac_title = (
                    "EvoluciÃ³n Mensual del CAC por Canal de Anuncios<br>"
                    "<sub>CAC mensual por canal = Costo total de anuncios (`Ads_cost`) del mes / Nuevos usuarios (`Total_users`) del mes. Fuente: `GA_ADS_CAMPAIGNS.csv`. PerÃ­odo global.</sub>"
                )
                fig = px.line(cac_by_channel_time, x='Date', y='CAC', color='Primary_channel_group',
                              title=fig_cac_title,
                              labels={'Date': 'Mes', 'CAC': 'CAC Promedio ($)', 'Primary_channel_group': 'Canal Primario'})
                safe_plotly_chart(fig)
            else:
                st.info("No hay suficientes datos para mostrar la evoluciÃ³n del CAC por canal.")
        else:
            st.warning("Columnas necesarias ('Ads_cost', 'Total_users', 'Primary_channel_group') no encontradas en `GA_ADS_CAMPAIGNS.csv` para calcular CAC.")
            if "CAC por Canal (columnas requeridas faltantes en datos de anuncios)" not in missing_data_points:
                missing_data_points.append("CAC por Canal (columnas requeridas faltantes en datos de anuncios)")
    else:
        st.info("No hay datos de anuncios en el perÃ­odo seleccionado para analizar costos de adquisiciÃ³n.")

    st.markdown("#### ğŸ¯ Costo por Lead (CPL)")
    st.warning("El cÃ¡lculo del Costo por Lead (CPL) requiere datos sobre la generaciÃ³n de leads (ej. 'LEADS_GENERATED') y el costo asociado a esa generaciÃ³n, que no estÃ¡n disponibles en los CSVs actuales. Formula: Costo de CampaÃ±a / NÃºmero de Leads Generados.")
    st.markdown("<div class='dashboard-subtext' style='font-size:0.8rem; text-align:center; margin-top:5px;'>Se necesitarÃ­a la columna `LEADS_GENERATED` en `GA_ADS_CAMPAIGNS.csv` o un dataset similar.</div>", unsafe_allow_html=True)

# Tab 7: NPS
with tab_nps:
    st.markdown("### ğŸ˜Š NPS (Net Promoter Score)")
    st.markdown("<div class='dashboard-subtext'>Midiendo la lealtad y satisfacciÃ³n del cliente.</div>", unsafe_allow_html=True)
    st.warning("""
    Los datos de Net Promoter Score (NPS) generalmente se recopilan a travÃ©s de encuestas directas a los clientes
    y no suelen estar presentes en los conjuntos de datos transaccionales o de anÃ¡lisis web estÃ¡ndar.
    """)
    st.markdown("""
    <div class='dashboard-subtext' style='font-size:0.8rem; text-align:left; margin-top:5px;'>
    Para mostrar anÃ¡lisis de NPS aquÃ­, necesitarÃ­as cargar un archivo CSV que contenga:
    <ul>
        <li>Identificador de cliente (ej. <code>USER_EMAIL</code>)</li>
        <li>PuntuaciÃ³n NPS (0-10)</li>
        <li>Fecha de la encuesta</li>
        <li>Opcionalmente, el canal por el cual se obtuvo la respuesta.</li>
    </ul>
    </div>
    """, unsafe_allow_html=True)


# Footer mejorado
st.markdown("---")
st.markdown(
    f"""
    <div style='text-align: center; padding: 1rem; color: #666;'>
        <p style='margin-bottom: 0.5rem;'>Customer Analytics Dashboard</p>
        <p style='font-size: 0.9rem; margin: 0;'>Ãšltima actualizaciÃ³n de datos en dashboard: {datetime.now().strftime("%Y-%m-%d %H:%M")}</p>
    </div>
    """,
    unsafe_allow_html=True
) 

# SecciÃ³n de PrÃ³ximas MÃ©tricas y Mejoras (reemplaza "Notas sobre Datos Faltantes")
# Lista de puntos especÃ­ficos a mostrar con el nuevo tono
planned_metrics_messages = [
    "LTV por canal de adquisiciÃ³n",
    "Tasa de Rebote (Bounce Rate)",
    "DuraciÃ³n Promedio de SesiÃ³n",
    "Tasa de Abandono de Carrito (CAR)",
    "Costo por Lead (CPL)",
    "Net Promoter Score (NPS)"
]

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ’¡ PrÃ³ximas MÃ©tricas y Mejoras")
st.sidebar.info("Estamos trabajando continuamente para enriquecer este dashboard. Algunas mÃ©tricas y anÃ¡lisis adicionales que estarÃ¡n disponibles pronto incluyen:")
for message in planned_metrics_messages:
    st.sidebar.markdown(f"- {message}")